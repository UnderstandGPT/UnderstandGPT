---
sidebar_position: 7
---

# Configuration Steps

---

## More Information Coming Soon!

Insights on how to approach and overcome these limitations will be shared on this wiki as we expand on it over time. 

### **This Page Is Still Under Construction!**

Your insights and contributions can help improve this content. Interested? Head over to our [GitHub](https://github.com/UnderstandGPT/UnderstandGPT) repo, read our `contribution.md` file, and make a pull request! Together, we can navigate the challenges and continue pushing the boundaries of what's possible with local LLMs.

Soon, this page will detail:

1.) How to run models efficiently (utilizing both GPU & CPU power wil GGML models)

2.) How to optimize performance with VRAM offloading/tuning.

3.) How to experiment running in CPU mode only. 

4.) How to adjust hyperparameters for different output results. 

5.) How to get the most out of your model's setup and configuration.  