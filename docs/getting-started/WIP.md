---
sidebar_position: 5
---

## More Information Coming Soon!

Insights on how to approach and overcome these limitations will be shared on this wiki as we expand on it over time. 

### **This Page Is Still Under Construction!**

Your insights and contributions can help improve this content. Interested? Head over to our [GitHub](https://github.com/UnderstandGPT/UnderstandGPT) repo, read our `contribution.md` file, and make a pull request! Together, we can navigate the challenges and continue pushing the boundaries of what's possible with local LLMs.

Listed below are the items we want on this page:
1. Where to find and download models
2. How does model size affect performance (with examples)
3. What is a fine tuned model vs a base model (with examples)
4. Basics of quanitzation
5. How do I know what models I can run?
6. Table of model size vs computation requirements (This will be a tricky one, ideally there are two tables, one for GPU inference and the other for CPU inference with some rough estimates)